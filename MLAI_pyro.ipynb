{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyro-ppl"
      ],
      "metadata": {
        "id": "dJ9PYO49LNK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear regression\n",
        "\n",
        "A linear model on the regression will provide as a basic estimation as to the performance of the data. The fast approximation will be a rough model and lack computational complexity."
      ],
      "metadata": {
        "id": "uyJ0OmuPWJLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zMlEZBY7K_gT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from functools import partial\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "\n",
        "# for CI testing\n",
        "smoke_test = ('CI' in os.environ)\n",
        "assert pyro.__version__.startswith('1.9.0')\n",
        "pyro.set_rng_seed(1)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('default')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from pyro.nn import PyroModule\n",
        "\n",
        "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
        "assert issubclass(PyroModule[nn.Linear], PyroModule)"
      ],
      "metadata": {
        "id": "RajosJynLfEq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "test = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n",
        "\n",
        "df = pd.concat([train, test])\n",
        "\n",
        "df['position'] = np.sqrt((df['longitude'] + df['latitude'])*(df['longitude'] + df['latitude']))\n",
        "df['value'] = np.log(df['median_house_value'])"
      ],
      "metadata": {
        "id": "5ns40jAlL_r5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(df[[\"position\",\n",
        "                        \"median_income\",\n",
        "                        \"total_rooms\",\n",
        "                        \"housing_median_age\",\n",
        "                        \"value\"]].values,dtype=torch.float)"
      ],
      "metadata": {
        "id": "qv_PimssMa4I"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = data[:,:-1]\n",
        "x_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2GwY_rnQ6ot",
        "outputId": "e0a6e6d5-1e2e-41bd-81fa-b736db50aee2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.0120e+01, 1.4936e+00, 5.6120e+03, 1.5000e+01],\n",
              "        [8.0070e+01, 1.8200e+00, 7.6500e+03, 1.9000e+01],\n",
              "        [8.0870e+01, 1.6509e+00, 7.2000e+02, 1.7000e+01],\n",
              "        ...,\n",
              "        [8.3400e+01, 2.2895e+00, 9.5600e+02, 1.0000e+01],\n",
              "        [8.3020e+01, 3.2708e+00, 9.6000e+01, 4.0000e+01],\n",
              "        [8.5210e+01, 8.5608e+00, 1.7650e+03, 4.2000e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_data = data[:,-1]\n",
        "y_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Do2I_cfS0qF",
        "outputId": "98320a86-5540-4a59-8c92-893c9772bd3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11.1110, 11.2910, 11.3586,  ..., 11.0349, 11.9984, 13.1224])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg_model = PyroModule[nn.Linear](4, 1)"
      ],
      "metadata": {
        "id": "oYzFR34YTAZQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
        "num_iterations = 1500 if not smoke_test else 2"
      ],
      "metadata": {
        "id": "sAEQHQtXTFaw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyro.clear_param_store()\n",
        "\n",
        "def train():\n",
        "    # run the model forward on the data\n",
        "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
        "    # calculate the mse loss\n",
        "    loss = loss_fn(y_pred, y_data)\n",
        "    # initialize gradients to zero\n",
        "    optim.zero_grad()\n",
        "    # backpropagate\n",
        "    loss.backward()\n",
        "    # take a gradient step\n",
        "    optim.step()\n",
        "    return loss\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = train()\n",
        "    if (j + 1) % 50 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
        "\n",
        "\n",
        "# Inspect learned parameters\n",
        "print(\"Learned parameters:\")\n",
        "for name, param in linear_reg_model.named_parameters():\n",
        "    print(name, param.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJOWzmAmTHcz",
        "outputId": "a1c8aebb-586c-4dd8-82e3-6d9c290b0609"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0050] loss: 7018119.5000\n",
            "[iteration 0100] loss: 20252.2383\n",
            "[iteration 0150] loss: 15700.3359\n",
            "[iteration 0200] loss: 13725.2666\n",
            "[iteration 0250] loss: 12146.3945\n",
            "[iteration 0300] loss: 10717.4707\n",
            "[iteration 0350] loss: 9438.5732\n",
            "[iteration 0400] loss: 8303.8457\n",
            "[iteration 0450] loss: 7307.1387\n",
            "[iteration 0500] loss: 6442.5371\n",
            "[iteration 0550] loss: 5703.3154\n",
            "[iteration 0600] loss: 5081.1318\n",
            "[iteration 0650] loss: 4565.8877\n",
            "[iteration 0700] loss: 4146.1191\n",
            "[iteration 0750] loss: 3809.6484\n",
            "[iteration 0800] loss: 3544.2466\n",
            "[iteration 0850] loss: 3338.2104\n",
            "[iteration 0900] loss: 3180.7695\n",
            "[iteration 0950] loss: 3062.3398\n",
            "[iteration 1000] loss: 2974.6438\n",
            "[iteration 1050] loss: 2910.7195\n",
            "[iteration 1100] loss: 2864.8540\n",
            "[iteration 1150] loss: 2832.4636\n",
            "[iteration 1200] loss: 2809.9531\n",
            "[iteration 1250] loss: 2794.5593\n",
            "[iteration 1300] loss: 2784.2026\n",
            "[iteration 1350] loss: 2777.3481\n",
            "[iteration 1400] loss: 2772.8853\n",
            "[iteration 1450] loss: 2770.0283\n",
            "[iteration 1500] loss: 2768.2280\n",
            "Learned parameters:\n",
            "weight [[1.4042939e-01 1.7525955e-01 2.1754422e-05 5.5610258e-03]]\n",
            "bias [-0.5956501]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Regression with stochastic variational inference"
      ],
      "metadata": {
        "id": "cc4LNl9XUSex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.nn import PyroSample\n",
        "\n",
        "\n",
        "class BayesianRegression(PyroModule):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
        "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
        "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
        "        mean = self.linear(x).squeeze(-1)\n",
        "        with pyro.plate(\"data\", x.shape[0]):\n",
        "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
        "        return mean"
      ],
      "metadata": {
        "id": "BzfYu5NjURwk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer.autoguide import AutoDiagonalNormal\n",
        "\n",
        "model = BayesianRegression(4, 1)\n",
        "guide = AutoDiagonalNormal(model)"
      ],
      "metadata": {
        "id": "3rX44filY30_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer import SVI, Trace_ELBO\n",
        "\n",
        "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
        "svi = SVI(model, guide, adam, loss=Trace_ELBO())"
      ],
      "metadata": {
        "id": "HGTe41JzaeBZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyro.clear_param_store()\n",
        "for j in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    loss = svi.step(x_data, y_data)\n",
        "    if j % 100 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIu1wqiuaj8o",
        "outputId": "9c8eaaf7-fe79-4eef-d443-2cb27958caf4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0001] loss: 357.8314\n",
            "[iteration 0101] loss: 144.7227\n",
            "[iteration 0201] loss: 424.3316\n",
            "[iteration 0301] loss: 156.1727\n",
            "[iteration 0401] loss: 5.7386\n",
            "[iteration 0501] loss: 33.6322\n",
            "[iteration 0601] loss: 4.2875\n",
            "[iteration 0701] loss: 6.7598\n",
            "[iteration 0801] loss: 6.7397\n",
            "[iteration 0901] loss: 9.5057\n",
            "[iteration 1001] loss: 11.8670\n",
            "[iteration 1101] loss: 28.0911\n",
            "[iteration 1201] loss: 3.2732\n",
            "[iteration 1301] loss: 27.0088\n",
            "[iteration 1401] loss: 37.1257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "guide.requires_grad_(False)\n",
        "\n",
        "for name, value in pyro.get_param_store().items():\n",
        "    print(name, pyro.param(name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbluZcK-aojN",
        "outputId": "153b72ae-f0c4-40c7-c585-a97b920c05b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoDiagonalNormal.loc Parameter containing:\n",
            "tensor([ 1.2649,  0.0878,  0.6300,  0.0044,  0.1625, -3.4021])\n",
            "AutoDiagonalNormal.scale tensor([0.0705, 0.0397, 0.1241, 0.0065, 0.0470, 0.0877])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer import Predictive\n",
        "\n",
        "\n",
        "def summary(samples):\n",
        "    site_stats = {}\n",
        "    for k, v in samples.items():\n",
        "        site_stats[k] = {\n",
        "            \"mean\": torch.mean(v, 0),\n",
        "            \"std\": torch.std(v, 0),\n",
        "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
        "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
        "        }\n",
        "    return site_stats\n",
        "\n",
        "\n",
        "predictive = Predictive(model, guide=guide, num_samples=800,\n",
        "                        return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))\n",
        "samples = predictive(x_data)\n",
        "pred_summary = summary(samples)"
      ],
      "metadata": {
        "id": "UUAbSWxjbDPG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu = pred_summary[\"_RETURN\"]\n",
        "y = pred_summary[\"obs\"]\n",
        "predictions = pd.DataFrame({\n",
        "    \"position\": x_data[:, 0],\n",
        "    \"median_income\": x_data[:, 1],\n",
        "    \"total_rooms\": x_data[:, 2],\n",
        "    \"housing_median_age\": x_data[:, 3],\n",
        "    \"mu_mean\": mu[\"mean\"],\n",
        "    \"mu_perc_5\": mu[\"5%\"],\n",
        "    \"mu_perc_95\": mu[\"95%\"],\n",
        "    \"y_mean\": y[\"mean\"],\n",
        "    \"y_perc_5\": y[\"5%\"],\n",
        "    \"y_perc_95\": y[\"95%\"],\n",
        "    \"true_val\": y_data,\n",
        "})"
      ],
      "metadata": {
        "id": "t3TDdrqgbiN5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
        "\n",
        "fig.suptitle(\"Regression line 90% CI\", fontsize=16)"
      ],
      "metadata": {
        "id": "qU5MkFv-crEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = samples[\"linear.weight\"]\n",
        "weight = weight.reshape(weight.shape[0], 3)\n",
        "gamma_within_africa = weight[:, 1] + weight[:, 2]\n",
        "gamma_outside_africa = weight[:, 1]\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "sns.distplot(gamma_within_africa, kde_kws={\"label\": \"African nations\"},)\n",
        "sns.distplot(gamma_outside_africa, kde_kws={\"label\": \"Non-African nations\"})\n",
        "fig.suptitle(\"Density of Slope : log(GDP) vs. Terrain Ruggedness\");"
      ],
      "metadata": {
        "id": "eWu0cwMOeKnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}